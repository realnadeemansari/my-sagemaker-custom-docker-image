{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0efbd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe3654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, encoder):\n",
    "    train = df[['Status', 'Levels', 'Rooms', 'Materials', 'Engagement', 'source']]\n",
    "    train_df = pd.get_dummies(train)\n",
    "    train_df = train_df.rename(columns = {'Status_no longer leaking, wet <1 day': 'Status_no longer leaking, wet less than 1 day',\n",
    "                                     'Status_no longer leaking, wet >1 day': 'Status_no longer leaking, wet more than 1 day'})\n",
    "    train_df.columns=train_df.columns.str.replace(r'[^0-9a-zA-Z ]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fa6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'C:/ml_projects/pm_projects/crawford/bdt_digital_desk/ml-ops/triage-nb/sagemaker/opt/ml/'\n",
    "\n",
    "input_path = prefix + 'input/data'\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "param_path = os.path.join(prefix, 'input/config/hyperparameters.json')\n",
    "\n",
    "# This algorithm has a single channel of input data called 'training'. Since we run in\n",
    "# File mode, the input files are copied to the directory specified here.\n",
    "channel_name='training'\n",
    "training_path = os.path.join(input_path, channel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e198a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(param_path, \"r\") as f:\n",
    "    ff = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37cb07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    print(\"Starting the training.\")\n",
    "    try:\n",
    "        with open(param_path, 'r') as tc:\n",
    "            training_params = json.load(tc)\n",
    "        \n",
    "        # Take the set of files and read them all into a single pandas dataframe\n",
    "        input_files = [os.path.join(training_path, file) for file in os.listdir(training_path)]\n",
    "        if len(input_files) == 0:\n",
    "            raise ValueError((\"There are no files in {}.\\n\" + \n",
    "                                'This usually indicates that the channel ({}) was incorrectly specified,\\n' +\n",
    "                              'the data specification in S3 was incorrectly specified or the role specified\\n' +\n",
    "                              'does not have permission to access the data.').format(training_path, channel_name))\n",
    "        \n",
    "        # Reading the training data.\n",
    "        raw_data = [ pd.read_csv(file) for file in input_files if file.endswith(\".csv\")]\n",
    "        \n",
    "        # Prepare the dataset.\n",
    "        train_data = pd.concat(raw_data)\n",
    "        train = train_data[['Status', 'Levels', 'Rooms', 'Materials', 'Engagement', 'source']]\n",
    "        train_df = pd.get_dummies(train)\n",
    "        train_df = train_df.rename(columns = {'Status_no longer leaking, wet <1 day': 'Status_no longer leaking, wet less than 1 day',\n",
    "                                        'Status_no longer leaking, wet >1 day': 'Status_no longer leaking, wet more than 1 day'})\n",
    "        train_df.columns=train_df.columns.str.replace(r'[^0-9a-zA-Z ]', ' ', regex=True)\n",
    "        encoder = LabelEncoder()\n",
    "        y_train = encoder.fit_transform(train_data[['labels']])\n",
    "        dtrain = xgb.DMatrix(data=train_df, label=y_train)\n",
    "\n",
    "        # Training the model.\n",
    "        model = xgb.train(training_params, dtrain)\n",
    "\n",
    "        # Save the model\n",
    "        with open(os.path.join(model_path, \"xgb-model.pkl\"), \"wb\") as out:\n",
    "            pickle.dump(model, out)\n",
    "        with open(os.path.join(model_path, \"xgb-encoder.pkl\"), \"wb\") as out:\n",
    "            pickle.dump(encoder, out)\n",
    "\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    except Exception as e:\n",
    "            # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print('Exception during training: ' + str(e) + '\\n' + trc, file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff860ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training.\n",
      "[05:22:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"n_gpus\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[05:22:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\.venvs\\jupyter_env\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\.venvs\\jupyter_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a244e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoringService(object):\n",
    "    model = None  # Where we keep the model when it's loaded\n",
    "    encoder = None\n",
    "    \n",
    "    @classmethod\n",
    "    def get_model(cls):\n",
    "        # Load Encoder if it is not loaded\n",
    "        if cls.encoder == None:\n",
    "            with open(os.path.join(model_path, \"xgb-encoder.pkl\"), \"rb\") as inp:\n",
    "                cls.encoder = pickle.load(inp)\n",
    "        \n",
    "        # Get the model object for this instance, loading it if it's not already loaded.\n",
    "        if cls.model == None:\n",
    "            with open(os.path.join(model_path,\"xgb-model.pkl\"), \"rb\") as inp:\n",
    "                cls.model = pickle.load(inp)\n",
    "        \n",
    "        # Return both models\n",
    "        return cls.encoder, cls.model\n",
    "\n",
    "    @classmethod\n",
    "    def predict(cls, input):\n",
    "        \"\"\"For the input, do the predictions and return them.\n",
    "\n",
    "        Args:\n",
    "            input (a pandas dataframe): The data on which to do the predictions. There will be\n",
    "                one prediction per row in the dataframe\"\"\"\n",
    "        encoder, model = cls.get_model()\n",
    "        prediction = model.predict(input)\n",
    "        pred_ = encoder.inverse_transform(prediction.astype(np.int32))\n",
    "        return pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e0bf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(input_object):\n",
    "    print(\"INPUT: \", input_object)\n",
    "    temp_lst = []\n",
    "    columns = ['Status active leak  currently wet', \n",
    "               'Status livable still in dwelling   building', \n",
    "               'Status livable temporarily displaced', \n",
    "               'Status no longer leaking  wet less than 1 day', \n",
    "               'Status no longer leaking  wet more than 1 day', \n",
    "               'Status no  no opening', \n",
    "               'Status unlivable displaced', \n",
    "               'Status yes  covered tarped', \n",
    "               'Status yes  uncovered not tarped', \n",
    "               'Levels 1 floor', \n",
    "               'Levels 2 floors or more', \n",
    "               'Levels no', \n",
    "               'Rooms 1 2 rooms', \n",
    "               'Rooms 3 rooms', \n",
    "               'Rooms 4 rooms', \n",
    "               'Rooms 5 or more rooms', \n",
    "               'Rooms no', \n",
    "               'Materials cabinets', \n",
    "               'Materials ceiling', \n",
    "               'Materials contents  personal belongings ', \n",
    "               'Materials exterior contents  grill  patio furniture  etc  ', \n",
    "               'Materials exterior structure', \n",
    "               'Materials fixtures', \n",
    "               'Materials floors', \n",
    "               'Materials hardscapes   fence', \n",
    "               'Materials no', \n",
    "               'Materials roof', \n",
    "               'Materials siding', \n",
    "               'Materials vinyl floor covering', \n",
    "               'Materials walls', \n",
    "               'Materials windows', \n",
    "               'Engagement attorney', \n",
    "               'Engagement contractor', \n",
    "               'Engagement no', \n",
    "               'Engagement public adjuster', \n",
    "               'source electrical', \n",
    "               'source fireplace', \n",
    "               'source lightning', \n",
    "               'source other', \n",
    "               'source stove', \n",
    "               'source unknown', \n",
    "               'source water', \n",
    "               'source wildfire', \n",
    "               'source wind']\n",
    "    input_obj_lst = [k+' '+v for k, v in input_object.items()]\n",
    "    for i in range(len(input_obj_lst)):\n",
    "        if input_obj_lst[i] == 'Status no longer leaking, wet <1 day':\n",
    "            input_obj_lst[i] = 'Status no longer leaking  wet less than 1 day'\n",
    "        elif input_obj_lst[i] == 'Status no longer leaking, wet >1 day':\n",
    "            input_obj_lst[i] = 'Status no longer leaking  wet more than 1 day'\n",
    "        input_obj_lst[i] = re.sub('[,.()-/]+', ' ', input_obj_lst[i])\n",
    "\n",
    "    for col in columns:\n",
    "        if col in input_obj_lst:\n",
    "            temp_lst.append(1)\n",
    "        else:\n",
    "            temp_lst.append(0)\n",
    "    df_test = pd.DataFrame(columns=columns, data=np.array(temp_lst).reshape(1, 44), index=None)\n",
    "    x_test = xgb.DMatrix(data=df_test)\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87e2863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Status', 'Levels', 'Rooms', 'Materials', 'Engagement', 'source']]\n",
    "x_data = {\"Status\": \"yes, covered/tarped\",\n",
    "          'Levels': \"no\",\n",
    "          \"Rooms\": \"1-2 rooms\",\n",
    "          \"Materials\": \"hardscapes / fence\",\n",
    "          \"Engagement\": \"contractor\",\n",
    "          \"source\": \"wind\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ba7c921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:  {'Status': 'yes, covered/tarped', 'Levels': 'no', 'Rooms': '1-2 rooms', 'Materials': 'hardscapes / fence', 'Engagement': 'contractor', 'source': 'wind'}\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_data(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b474ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x1d72147e248>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ab39bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ScoringService.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "268f60e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LA'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d4e4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018df587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052848c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "162a65eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost==1.5.2\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "     -------------------------------------- 106.6/106.6 MB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\.venvs\\jupyter_env\\lib\\site-packages (from xgboost==1.5.2) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\.venvs\\jupyter_env\\lib\\site-packages (from xgboost==1.5.2) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost==1.5.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0bb3cf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb42b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "bash_command = \"tar -cvpzf model.tar.gz xgb-model.pkl xgb-encoder.pkl\"\n",
    "process = subprocess.Popen(bash_command.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfba61aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e210cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7bbbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
